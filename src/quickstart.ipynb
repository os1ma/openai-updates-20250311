{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\", override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under the shimmering light of the moon, a magical unicorn galloped through the stardust, weaving dreams of joy for every sleeping child.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_67d4e138799c8190a77a57f0cab3fddf0495dc9e6c906699\",\n",
      "  \"created_at\": 1742004536.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_67d4e138eecc81908421f3e9288fdf740495dc9e6c906699\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Under the shimmering light of the moon, a magical unicorn galloped through the stardust, weaving dreams of joy for every sleeping child.\",\n",
      "          \"type\": \"output_text\"\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null\n",
      "  },\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 36,\n",
      "    \"output_tokens\": 29,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 65,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.to_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On March 15, 2025, the world observed International Long COVID Awareness Day, highlighting the ongoing efforts to support individuals affected by long COVID. This day serves as a reminder of the resilience and determination of patients, caregivers, and advocates working together to raise awareness and improve resources for those impacted by the condition. ([nitajain.com](https://www.nitajain.com/p/international-long-covid-awareness?utm_source=openai))\n",
      "\n",
      "In a heartwarming story from South Korea, a mother named Olivia Kim has been teaching her young children to memorize Bible verses, instilling in them a deep appreciation for their faith. Starting when her son David was just 18 months old, Olivia's dedication has led him to memorize between 350 to 400 Bible verses by the age of seven. This inspiring example underscores the importance of nurturing spiritual growth from an early age. ([sabbathprograms.com](https://sabbathprograms.com/mission-story/storing-gods-word-adult-mission-story-march-15-2025?utm_source=openai))\n",
      "\n",
      "Additionally, the United States has seen a significant investment in its semiconductor industry. Taiwan Semiconductor Manufacturing Co. announced a substantial investment over a four-year period to build cutting-edge chip-making facilities in the U.S. This development aims to revitalize domestic semiconductor manufacturing, enhancing technological capabilities and economic growth. ([capitolhillprayer.org](https://www.capitolhillprayer.org/publications-posts/the-daily-brief-march-5-2025?utm_source=openai))\n",
      "\n",
      "These stories from March 15, 2025, reflect positive developments in health awareness, personal growth, and technological advancement. \n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"web_search_preview\"}],\n",
    "    input=\"What was a positive news story from today?\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_67d4e27f863c81908f54443a45c910f10dd55113577b3efb\",\n",
      "  \"created_at\": 1742004863.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"ws_67d4e2800bf881908dd1f41acfbf40780dd55113577b3efb\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"web_search_call\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_67d4e281e85081909b7a7ec09952deda0dd55113577b3efb\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [\n",
      "            {\n",
      "              \"end_index\": 455,\n",
      "              \"start_index\": 358,\n",
      "              \"title\": \"International Long COVID Awareness Day: March 15, 2025\",\n",
      "              \"type\": \"url_citation\",\n",
      "              \"url\": \"https://www.nitajain.com/p/international-long-covid-awareness?utm_source=openai\"\n",
      "            },\n",
      "            {\n",
      "              \"end_index\": 1028,\n",
      "              \"start_index\": 892,\n",
      "              \"title\": \"Storing God’s Word : Adult Mission Story for March 15, 2025 | Sabbath Programs\",\n",
      "              \"type\": \"url_citation\",\n",
      "              \"url\": \"https://sabbathprograms.com/mission-story/storing-gods-word-adult-mission-story-march-15-2025?utm_source=openai\"\n",
      "            },\n",
      "            {\n",
      "              \"end_index\": 1540,\n",
      "              \"start_index\": 1414,\n",
      "              \"title\": \"The Daily Brief — Capitol Hill Prayer Partners\",\n",
      "              \"type\": \"url_citation\",\n",
      "              \"url\": \"https://www.capitolhillprayer.org/publications-posts/the-daily-brief-march-5-2025?utm_source=openai\"\n",
      "            }\n",
      "          ],\n",
      "          \"text\": \"On March 15, 2025, the world observed International Long COVID Awareness Day, highlighting the ongoing efforts to support individuals affected by long COVID. This day serves as a reminder of the resilience and determination of patients, caregivers, and advocates working together to raise awareness and improve resources for those impacted by the condition. ([nitajain.com](https://www.nitajain.com/p/international-long-covid-awareness?utm_source=openai))\\n\\nIn a heartwarming story from South Korea, a mother named Olivia Kim has been teaching her young children to memorize Bible verses, instilling in them a deep appreciation for their faith. Starting when her son David was just 18 months old, Olivia's dedication has led him to memorize between 350 to 400 Bible verses by the age of seven. This inspiring example underscores the importance of nurturing spiritual growth from an early age. ([sabbathprograms.com](https://sabbathprograms.com/mission-story/storing-gods-word-adult-mission-story-march-15-2025?utm_source=openai))\\n\\nAdditionally, the United States has seen a significant investment in its semiconductor industry. Taiwan Semiconductor Manufacturing Co. announced a substantial investment over a four-year period to build cutting-edge chip-making facilities in the U.S. This development aims to revitalize domestic semiconductor manufacturing, enhancing technological capabilities and economic growth. ([capitolhillprayer.org](https://www.capitolhillprayer.org/publications-posts/the-daily-brief-march-5-2025?utm_source=openai))\\n\\nThese stories from March 15, 2025, reflect positive developments in health awareness, personal growth, and technological advancement. \",\n",
      "          \"type\": \"output_text\"\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"web_search_preview\",\n",
      "      \"search_context_size\": \"medium\",\n",
      "      \"user_location\": {\n",
      "        \"type\": \"approximate\",\n",
      "        \"city\": null,\n",
      "        \"country\": \"US\",\n",
      "        \"region\": null,\n",
      "        \"timezone\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null\n",
      "  },\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 328,\n",
      "    \"output_tokens\": 361,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 689,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.to_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下は、比較的シンプルなアルゴリズム問題の例です。\n",
      "\n",
      "【問題】 Two Sum 問題\n",
      "\n",
      "【内容】\n",
      "整数の配列 nums と整数 target が与えられます。nums の中から 2 つの異なる要素を選び、その和が target と一致するような組み合わせを見つけ、これら 2 つの要素の「インデックス」を返してください。各テストケースでは必ず正解が 1 組存在すると仮定します。同じ要素を 2 回使うことはできません。\n",
      "\n",
      "【例】\n",
      "入力：\n",
      "　nums = [2, 7, 11, 15]\n",
      "　target = 9\n",
      "\n",
      "出力：\n",
      "　[0, 1]\n",
      "\n",
      "（解説：nums[0] と nums[1]、つまり 2 + 7 = 9 となるので、この 2 つのインデックスを返します。）\n",
      "\n",
      "【制約】\n",
      "1. 配列 nums のサイズは 2 以上。\n",
      "2. 配列内の各要素は整数。\n",
      "3. 返すインデックスは配列の先頭を 0 として考えます。\n",
      "4. 各テストケースで必ず 1 組の答えが存在する（解が複数ある場合でも、どれか 1 組を返せばよい）。\n",
      "\n",
      "【ヒント】\n",
      "・力任せの探索（すべての組み合わせをチェックする）アルゴリズムは実装が簡単ですが、配列のサイズが大きい場合は効率が悪くなる可能性があります。\n",
      "・より効率的な解法として、探索中に補数を管理するハッシュテーブル（辞書）を用いる方法があります。\n",
      "\n",
      "以上の仕様に基づいて、アルゴリズムを実装してみてください。\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"o3-mini\",\n",
    "    input=\"簡単なアルゴリズムの問題を1つ考えて\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of March 15, 2025, here are some positive news stories:\n",
      "\n",
      "- **Waco ISD Fine Arts Department Receives State Honors**: The Waco Independent School District's Fine Arts Department was recognized with state honors for its elementary, middle, and high school theater programs. ([kwtx.com](https://www.kwtx.com/2025/03/14/good-news-friday-march-15-2025/?utm_source=openai))\n",
      "\n",
      "- **Killeen Citizens Academy Graduates 11th Class**: The 11th class of the Killeen Citizens Academy graduated, marking the completion of a free program that began in 2014 to help citizens better understand city operations. ([kwtx.com](https://www.kwtx.com/2025/03/14/good-news-friday-march-15-2025/?utm_source=openai))\n",
      "\n",
      "- **Shiv Parmar Wins 2025 Texas Cup Invitational**: Shiv Parmar of Selma, Texas, won the 2025 Texas Cup Invitational at Rayburn Resort, finishing with a 9-under 201 for the tournament. ([kwtx.com](https://www.kwtx.com/2025/03/14/good-news-friday-march-15-2025/?utm_source=openai))\n",
      "\n",
      "- **Gaza Ceasefire Agreement**: Israel and Hamas agreed to a ceasefire and hostage release deal, set to last an initial six weeks, aiming to halt a conflict that has claimed many lives. ([positive.news](https://www.positive.news/society/good-news-stories-from-week-03-of-2025/?utm_source=openai))\n",
      "\n",
      "- **Indonesia Launches Free Meals Program**: Indonesia initiated an ambitious program to provide free meals to more than a quarter of its population, targeting 82.9 million people by 2029. ([positive.news](https://www.positive.news/society/good-news-stories-from-week-03-of-2025/?utm_source=openai))\n",
      "\n",
      "- **Thailand Legalizes Same-Sex Marriage**: Thailand became the first country in Southeast Asia to legalize same-sex marriage, granting equal rights to same-sex couples. ([positive.news](https://www.positive.news/society/good-news-stories-from-week-04-of-2025/?utm_source=openai))\n",
      "\n",
      "- **Fossil Fuels' Decline in EU Energy**: For the first time, solar energy generated more electricity than coal in the European Union, indicating a significant shift towards renewable energy sources. ([positive.news](https://www.positive.news/society/good-news-stories-from-week-04-of-2025/?utm_source=openai))\n",
      "\n",
      "These stories highlight various positive developments across different sectors and regions. \n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-search-preview\",\n",
    "    web_search_options={},\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What was a positive news story from today?\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-765dbc57-3c3c-4998-b8ad-d29a042afa52\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"As of March 15, 2025, here are some positive news stories:\\n\\n- **Waco ISD Fine Arts Department Receives State Honors**: The Waco Independent School District's Fine Arts Department was recognized with state honors for its elementary, middle, and high school theater programs. ([kwtx.com](https://www.kwtx.com/2025/03/14/good-news-friday-march-15-2025/?utm_source=openai))\\n\\n- **Killeen Citizens Academy Graduates 11th Class**: The 11th class of the Killeen Citizens Academy graduated, marking the completion of a free program that began in 2014 to help citizens better understand city operations. ([kwtx.com](https://www.kwtx.com/2025/03/14/good-news-friday-march-15-2025/?utm_source=openai))\\n\\n- **Shiv Parmar Wins 2025 Texas Cup Invitational**: Shiv Parmar of Selma, Texas, won the 2025 Texas Cup Invitational at Rayburn Resort, finishing with a 9-under 201 for the tournament. ([kwtx.com](https://www.kwtx.com/2025/03/14/good-news-friday-march-15-2025/?utm_source=openai))\\n\\n- **Gaza Ceasefire Agreement**: Israel and Hamas agreed to a ceasefire and hostage release deal, set to last an initial six weeks, aiming to halt a conflict that has claimed many lives. ([positive.news](https://www.positive.news/society/good-news-stories-from-week-03-of-2025/?utm_source=openai))\\n\\n- **Indonesia Launches Free Meals Program**: Indonesia initiated an ambitious program to provide free meals to more than a quarter of its population, targeting 82.9 million people by 2029. ([positive.news](https://www.positive.news/society/good-news-stories-from-week-03-of-2025/?utm_source=openai))\\n\\n- **Thailand Legalizes Same-Sex Marriage**: Thailand became the first country in Southeast Asia to legalize same-sex marriage, granting equal rights to same-sex couples. ([positive.news](https://www.positive.news/society/good-news-stories-from-week-04-of-2025/?utm_source=openai))\\n\\n- **Fossil Fuels' Decline in EU Energy**: For the first time, solar energy generated more electricity than coal in the European Union, indicating a significant shift towards renewable energy sources. ([positive.news](https://www.positive.news/society/good-news-stories-from-week-04-of-2025/?utm_source=openai))\\n\\nThese stories highlight various positive developments across different sectors and regions. \",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": [\n",
      "          {\n",
      "            \"type\": \"url_citation\",\n",
      "            \"url_citation\": {\n",
      "              \"end_index\": 369,\n",
      "              \"start_index\": 274,\n",
      "              \"title\": \"Good News Friday: March 15, 2025\",\n",
      "              \"url\": \"https://www.kwtx.com/2025/03/14/good-news-friday-march-15-2025/?utm_source=openai\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"url_citation\",\n",
      "            \"url_citation\": {\n",
      "              \"end_index\": 689,\n",
      "              \"start_index\": 594,\n",
      "              \"title\": \"Good News Friday: March 15, 2025\",\n",
      "              \"url\": \"https://www.kwtx.com/2025/03/14/good-news-friday-march-15-2025/?utm_source=openai\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"url_citation\",\n",
      "            \"url_citation\": {\n",
      "              \"end_index\": 971,\n",
      "              \"start_index\": 876,\n",
      "              \"title\": \"Good News Friday: March 15, 2025\",\n",
      "              \"url\": \"https://www.kwtx.com/2025/03/14/good-news-friday-march-15-2025/?utm_source=openai\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"url_citation\",\n",
      "            \"url_citation\": {\n",
      "              \"end_index\": 1269,\n",
      "              \"start_index\": 1159,\n",
      "              \"title\": \"What went right this week: tentative hope in Gaza, plus more - Positive News\",\n",
      "              \"url\": \"https://www.positive.news/society/good-news-stories-from-week-03-of-2025/?utm_source=openai\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"url_citation\",\n",
      "            \"url_citation\": {\n",
      "              \"end_index\": 1570,\n",
      "              \"start_index\": 1460,\n",
      "              \"title\": \"What went right this week: tentative hope in Gaza, plus more - Positive News\",\n",
      "              \"url\": \"https://www.positive.news/society/good-news-stories-from-week-03-of-2025/?utm_source=openai\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"url_citation\",\n",
      "            \"url_citation\": {\n",
      "              \"end_index\": 1852,\n",
      "              \"start_index\": 1742,\n",
      "              \"title\": \"What went right this week: a global work reset, plus more - Positive News\",\n",
      "              \"url\": \"https://www.positive.news/society/good-news-stories-from-week-04-of-2025/?utm_source=openai\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"url_citation\",\n",
      "            \"url_citation\": {\n",
      "              \"end_index\": 2164,\n",
      "              \"start_index\": 2054,\n",
      "              \"title\": \"What went right this week: a global work reset, plus more - Positive News\",\n",
      "              \"url\": \"https://www.positive.news/society/good-news-stories-from-week-04-of-2025/?utm_source=openai\"\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1742005096,\n",
      "  \"model\": \"gpt-4o-search-preview-2025-03-11\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 564,\n",
      "    \"prompt_tokens\": 9,\n",
      "    \"total_tokens\": 573,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.to_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-a68c2706-e85a-4b14-8a88-f0b022ba6fc2\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"こんにちは！お元気ですか？ \",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": []\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1742005180,\n",
      "  \"model\": \"gpt-4o-search-preview-2025-03-11\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 9,\n",
      "    \"prompt_tokens\": 2,\n",
      "    \"total_tokens\": 11,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-search-preview\",\n",
    "    web_search_options={},\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"こんにちは！\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.to_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseCreatedEvent(response=Response(id='resp_67d4e44e1f4481908d9dfd517b4ee1840a496a7b7484433b', created_at=1742005326.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-2024-08-06', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=None, user=None, store=True), type='response.created')\n",
      "ResponseInProgressEvent(response=Response(id='resp_67d4e44e1f4481908d9dfd517b4ee1840a496a7b7484433b', created_at=1742005326.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-2024-08-06', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=None, user=None, store=True), type='response.in_progress')\n",
      "ResponseOutputItemAddedEvent(item=ResponseOutputMessage(id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', content=[], role='assistant', status='in_progress', type='message'), output_index=0, type='response.output_item.added')\n",
      "ResponseContentPartAddedEvent(content_index=0, item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, part=ResponseOutputText(annotations=[], text='', type='output_text'), type='response.content_part.added')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=\"That's\", item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' a', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' fun', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' tongue', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' tw', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='ister', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='!', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' Here', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' you', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' go', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=':', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' \"', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='double', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bubble', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bath', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=',', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' double', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bubble', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bath', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=',', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' double', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bubble', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bath', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=',', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' double', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bubble', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bath', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=',', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' double', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bubble', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bath', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=',', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' double', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bubble', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bath', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=',', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' double', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bubble', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bath', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=',', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' double', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bubble', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bath', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=',', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' double', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bubble', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bath', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=',', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' double', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bubble', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bath', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='.\"', item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, type='response.output_text.delta')\n",
      "ResponseTextDoneEvent(content_index=0, item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, text='That\\'s a fun tongue twister! Here you go: \"double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath.\"', type='response.output_text.done')\n",
      "ResponseContentPartDoneEvent(content_index=0, item_id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', output_index=0, part=ResponseOutputText(annotations=[], text='That\\'s a fun tongue twister! Here you go: \"double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath.\"', type='output_text'), type='response.content_part.done')\n",
      "ResponseOutputItemDoneEvent(item=ResponseOutputMessage(id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', content=[ResponseOutputText(annotations=[], text='That\\'s a fun tongue twister! Here you go: \"double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath.\"', type='output_text')], role='assistant', status='completed', type='message'), output_index=0, type='response.output_item.done')\n",
      "ResponseCompletedEvent(response=Response(id='resp_67d4e44e1f4481908d9dfd517b4ee1840a496a7b7484433b', created_at=1742005326.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-2024-08-06', object='response', output=[ResponseOutputMessage(id='msg_67d4e44ea5488190906957b651897b8d0a496a7b7484433b', content=[ResponseOutputText(annotations=[], text='That\\'s a fun tongue twister! Here you go: \"double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath, double bubble bath.\"', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=35, output_tokens=53, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=88, input_tokens_details={'cached_tokens': 0}), user=None, store=True), type='response.completed')\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "stream = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say 'double bubble bath' ten times fast.\",\n",
    "        },\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunResult(input='Hola, ¿cómo estás?', new_items=[HandoffCallItem(agent=Agent(name='Triage agent', instructions='Handoff to the appropriate agent based on the language of the request.', handoff_description=None, handoffs=[Agent(name='Spanish agent', instructions='You only speak Spanish.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None), Agent(name='English agent', instructions='You only speak English', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None)], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None), raw_item=ResponseFunctionToolCall(id='fc_67d4e513f51c81908de3df35bacd918103029d8c52f06f40', arguments='{}', call_id='call_ETawfkmf96wMnPCW07jqyNMu', name='transfer_to_spanish_agent', type='function_call', status='completed'), type='handoff_call_item'), HandoffOutputItem(agent=Agent(name='Triage agent', instructions='Handoff to the appropriate agent based on the language of the request.', handoff_description=None, handoffs=[Agent(name='Spanish agent', instructions='You only speak Spanish.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None), Agent(name='English agent', instructions='You only speak English', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None)], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None), raw_item={'call_id': 'call_ETawfkmf96wMnPCW07jqyNMu', 'output': \"{'assistant': 'Spanish agent'}\", 'type': 'function_call_output'}, source_agent=Agent(name='Triage agent', instructions='Handoff to the appropriate agent based on the language of the request.', handoff_description=None, handoffs=[Agent(name='Spanish agent', instructions='You only speak Spanish.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None), Agent(name='English agent', instructions='You only speak English', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None)], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None), target_agent=Agent(name='Spanish agent', instructions='You only speak Spanish.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None), type='handoff_output_item'), MessageOutputItem(agent=Agent(name='Spanish agent', instructions='You only speak Spanish.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None), raw_item=ResponseOutputMessage(id='msg_67d4e5147ab08190ac3c39c5bc814fa303029d8c52f06f40', content=[ResponseOutputText(annotations=[], text='¡Hola! Estoy bien, gracias. ¿Y tú, cómo estás?', type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')], raw_responses=[ModelResponse(output=[ResponseFunctionToolCall(id='fc_67d4e513f51c81908de3df35bacd918103029d8c52f06f40', arguments='{}', call_id='call_ETawfkmf96wMnPCW07jqyNMu', name='transfer_to_spanish_agent', type='function_call', status='completed')], usage=Usage(requests=1, input_tokens=303, output_tokens=14, total_tokens=317), referenceable_id='resp_67d4e5137cb0819096089a1d28230a6f03029d8c52f06f40'), ModelResponse(output=[ResponseOutputMessage(id='msg_67d4e5147ab08190ac3c39c5bc814fa303029d8c52f06f40', content=[ResponseOutputText(annotations=[], text='¡Hola! Estoy bien, gracias. ¿Y tú, cómo estás?', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=72, output_tokens=16, total_tokens=88), referenceable_id='resp_67d4e51436c481908aa7a9cb9f50001b03029d8c52f06f40')], final_output='¡Hola! Estoy bien, gracias. ¿Y tú, cómo estás?', input_guardrail_results=[], output_guardrail_results=[], _last_agent=Agent(name='Spanish agent', instructions='You only speak Spanish.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None))\n",
      "HandoffCallItem(agent=Agent(name='Triage agent', instructions='Handoff to the appropriate agent based on the language of the request.', handoff_description=None, handoffs=[Agent(name='Spanish agent', instructions='You only speak Spanish.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None), Agent(name='English agent', instructions='You only speak English', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None)], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None), raw_item=ResponseFunctionToolCall(id='fc_67d4e513f51c81908de3df35bacd918103029d8c52f06f40', arguments='{}', call_id='call_ETawfkmf96wMnPCW07jqyNMu', name='transfer_to_spanish_agent', type='function_call', status='completed'), type='handoff_call_item')\n",
      "HandoffOutputItem(agent=Agent(name='Triage agent', instructions='Handoff to the appropriate agent based on the language of the request.', handoff_description=None, handoffs=[Agent(name='Spanish agent', instructions='You only speak Spanish.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None), Agent(name='English agent', instructions='You only speak English', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None)], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None), raw_item={'call_id': 'call_ETawfkmf96wMnPCW07jqyNMu', 'output': \"{'assistant': 'Spanish agent'}\", 'type': 'function_call_output'}, source_agent=Agent(name='Triage agent', instructions='Handoff to the appropriate agent based on the language of the request.', handoff_description=None, handoffs=[Agent(name='Spanish agent', instructions='You only speak Spanish.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None), Agent(name='English agent', instructions='You only speak English', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None)], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None), target_agent=Agent(name='Spanish agent', instructions='You only speak Spanish.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None), type='handoff_output_item')\n",
      "MessageOutputItem(agent=Agent(name='Spanish agent', instructions='You only speak Spanish.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None), raw_item=ResponseOutputMessage(id='msg_67d4e5147ab08190ac3c39c5bc814fa303029d8c52f06f40', content=[ResponseOutputText(annotations=[], text='¡Hola! Estoy bien, gracias. ¿Y tú, cómo estás?', type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner\n",
    "import asyncio\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"Spanish agent\",\n",
    "    instructions=\"You only speak Spanish.\",\n",
    ")\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"English agent\",\n",
    "    instructions=\"You only speak English\",\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage agent\",\n",
    "    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n",
    "    handoffs=[spanish_agent, english_agent],\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    result = await Runner.run(triage_agent, input=\"Hola, ¿cómo estás?\")\n",
    "    print(result)\n",
    "\n",
    "    for i in result.new_items:\n",
    "        print(i)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()\n",
    "\n",
    "# ¡Hola! Estoy bien, gracias por preguntar. ¿Y tú, cómo estás?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the scarecrow win an award?\n",
      "\n",
      "Because he was outstanding in his field!\n",
      "The joke is a play on words, known as a pun. It uses the double meaning of \"outstanding.\" \n",
      "\n",
      "1. **Literal Meaning**: A scarecrow is placed in a field to scare away birds, so it is literally \"standing out\" there.\n",
      "2. **Figurative Meaning**: \"Outstanding\" also means exceptional or excellent, suggesting the scarecrow did something particularly great to earn an award.\n",
      "\n",
      "The humor comes from the clever twist in language that connects both meanings. Puns often create an unexpected or humorous effect by linking unrelated concepts, which can catch the listener off guard.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=\"tell me a joke\",\n",
    "    store=True,\n",
    ")\n",
    "print(response.output_text)\n",
    "\n",
    "second_response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    previous_response_id=response.id,\n",
    "    input=[{\"role\": \"user\", \"content\": \"explain why this is funny.\"}],\n",
    ")\n",
    "print(second_response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "spanish_agent = Agent(\n",
    "    name=\"Spanish agent\",\n",
    "    instructions=\"You only speak Spanish.\",\n",
    ")\n",
    "print(spanish_agent.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
